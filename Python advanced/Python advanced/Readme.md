Часть 1: анализ данных
numpy и pandas
Задание
 возьмите данные по вызовам пожарных служб в Москве за 2015-2019 годы:
https://video.ittensive.com/python-advanced/data-5283-2019-10-04.utf.csv
Получите из них фрейм данных (таблицу значений). По этому фрейму вычислите среднее значение вызовов пожарных машин в месяц в одном округе Москвы, округлив до целых
Примечание: найдите среднее значение вызовов, без учета года

Решение:
1)	подключаем библиотеку pandas
2)	получаем данные, в качестве разделителя указываем точку с запятой
3)	в серии данных, в которой указано количество звонков в месяц, в одном административном округе, мы получаем среднее значение с помощью метода mean()
4)	затем выводим его, как целое число

Индексы и объединение фреймов
Задание

Получите данные по безработице в Москве:
https://video.ittensive.com/python-advanced/data-9753-2019-07-25.utf.csv
Объедините эти данные индексами (Месяц/Год) с данными из предыдущего задания (вызовы пожарных) для Центральный административный округ:
https://video.ittensive.com/python-advanced/data-5283-2019-10-04.utf.csv
Найдите значение поля UnemployedMen в том месяце, когда было меньше всего вызовов в Центральном административном округе.


Решение:
1)	получаем необходимые для нас данные о вызовах
2)	в данных вызовов пожарных по округам, в качестве индексов используем округа, год и месяц
3)	в данных о работоспособности населения, качестве индексов используем год и период
4)	переименовываем индексы, на идентичные как в данных о вызовах
5)	выбираем все значения, где в названии присутствует "Центральный административный округу"
6)	объединяем два набора данных по левым и правым индексам
7)	отбрасываем текущий индекс
8)	назначаем новый индекс по числу вызовов
9)	сортируем данные по этому индексу
10)	выведем одно значение из серии "UnemployedMen", начиная с нулевого индекса

Фильтрация и изменение данных
Задание
Получите данные по безработице в Москве:
https://video.ittensive.com/python-advanced/data-9753-2019-07-25.utf.csv
Найдите, с какого года процент людей с ограниченными возможностями (UnemployedDisabled) среди всех безработных (UnemployedTotal) стал меньше 2%.
Решение:
1)	подключаем библиотеку pandas
2)	Узнаём, чему равно 2 процента, и выбираем те значения которые больше двух с помощью lambda функции, 100 умножаем на произведение между UnemployedDisabled и UnemployedTotal
3)	в качестве индекса используем серию данных "Year"
4)	сортируем данные по индексу
5)	выбираем все значения до первого, начиная с нулевого
6)	выводим ответ
Линейная регрессия
Задание
Возьмите данные по безработице в городе Москва:
video.ittensive.com/python-advanced/data-9753-2019-07-25.utf.csv
Сгруппируйте данные по годам, и, если в году меньше 6 значений, отбросьте эти годы.
Постройте модель линейной регрессии по годам среднего значения отношения UnemployedDisabled к UnemployedTotal (процента людей с ограниченными возможностями) за месяц и ответьте, какое ожидается значение процента безработных инвалидов в 2020 году при сохранении текущей политики города Москвы?
Ответ округлите до сотых. Например, 2,32
Решение:
1)	подключаем необходимые фреймворки
2)	рассчитываем отношение в процентах
3)	для фильтрации, выполняем группировку по году, используем метод фильтрации с лямбда функцией которая принимает на вход группу данных
4)	считаем число строк, которое вошло в группу данных x, и это число строк должно быть больше 5, так как фильтр возвращает не группу, а сами данные, ещё раз группируем и находим среднее значение согласно условию
5)	изменяем форму, и преобразуем данные в двумерный массив
6)	загружаем модель линейной регрессии
7)	добавляем в неё наши значения
8)	добавляем график модели
9)	вычисляем значение для 2020г, делаем из него двумерный массив
10)	выводим ответ
Часть 2: импорт и парсинг данных
Импорт данных
Задание
Изучите API Геокодера Яндекса
tech.yandex.ru/maps/geocoder/doc/desc/concepts/input_params-docpage/
и получите ключ API для него в кабинете разработчика.
Выполните запрос к API и узнайте долготу точки на карте (Point) для города Самара.
Внимание: активация ключа Геокодера Яндекса может занимать несколько часов (до суток).
В качестве запасного варианта можно использовать этот ключ - 3f355b88-81e9-4bbf-a0a4-eb687fdea256 - он только для выполнения этого задания!
Решение:
1)	подключаем библиотеки requests (для выполнение запроса) и json (для получения контента) 
2)	в качестве геокода используем нужный нам город: "Самара"
3)	apikey берём предоставленный нам в задании,
4)	формат ответа указываем json,
5)	результат, максимальное количество возвращаемых объектов указываем 1 (по умолчанию 10)
6)	полученный ответ присваиваем в объект geo
7)	находим точку центра, последовательно сокращая наш объект

Парсинг данных
Задание
Получите данные по котировкам акций со страницы:
mfd.ru/marketdata/?id=5&group=16&mode=3&sortHeader=name&sortOrder=1&selectedDate=01.11.2019
и найдите, по какому тикеру был максимальный рост числа сделок (в процентах) за 1 ноября 2019 года.


Решение:
1)	подключаем нужные нам библиотеки
2)	получаем данные со страницы, по указанной ссылке
3)	преобразуем её в объект
4)	получаем данные из тега "table", id у которого имеет значение "marketDatalist"
5)	создаём список, где будем хранить данные строк
6)	получаем все данные, которые имеют тег 'tr'
7)	обходим циклом полученные данные, из каждой строки (тега "td"), получаем содержимое в виде текста
8)	в строку (table_row), с помощью генератора осуществляем добавления текста из ячеек (table_data), 
9)	в table_data обновляем данные из содержимого с тегом 'td'
10)	с помощью параметра strip=True убираем переносы строк и пробелы
11)	если длина строки больше нуля, мы в список строк, добавляем полученную нами из table_rows строку
12)	создаём фрейм данных куда добавляем наш список "rows", присваиваем нужные нам имена для колонок
13)	в созданный фрейм, из серии данных "Сделки" добавляем только те значения, которые не равны "N/A"
14)	из столбца "процент сделок" все символы "дефис" заменяем на символ "минус", так как их наличие как они затрудняют сортировку
15)	в получившихся строках знак процента % заменяем на пустое значения
16)	полученные данные преобразуем к типу float
17)	в этом фрейме данных из столбца "% сделок" формируем индекс
18)	сортируем данные по индексу, в порядке убывания (ascending=False)
19)	выводим первую позицию, из серии данных "Тикер", это и является ответом

Веб-скрепинг
Задание
Используя парсинг данных с маркетплейса beru.ru, найдите, на сколько литров отличается общий объем холодильников Саратов 263 и Саратов 452?
Для парсинга можно использовать зеркало страницы beru.ru с результатами для холодильников Саратов по адресу:
video.ittensive.com/data/018-python-advanced/beru.ru/
Решение:
1)	задаём User-Agent и указываем ссылку на сайт
2)	получаем данные со страницы, на которой находятся ссылки на страницы холодильников
3)	преобразуем их в объект
4)	получаем все теги "a" с классом "_3ioN70chUh Usp3kX1MNT _3Uc73lzxcf", именно в них хранятся ссылки на детальные страницы холодильников
5)	перебираем это список 
6)	если у нас в виде строкового значения появляется запись "Саратов 263", получаем данные из атрибута "href" этой ссылки, это путь к детальной странице холодильника
7)	аналогичную операцию проделываем с "Саратов 452
8)	создаём функцию, которая на вход принимает атрибут "href"
9)	по нему выстраиваем адрес для получения контента с этой странице, детальной странице холодильника
10)	преобразуем эти данные в объект
11)	из этого объекта функция получает все данные, которые имеют тег span, c классом"_112Tad-7AP"
12)	далее создаётся генератор, который в третьем элементе volume.get_text() (именно под этим индексом находится нужный нам объём voluem) c помощью метода get_text() приводим значение к строковому значению
13)	обходим volume[2].get_text() циклом и получаем все символы строки, и если символ цифра, то мы его вернём
14)	с помощью ''.join объединяем эти символы, через пустую строку, таким образом мы выделили все цифры из строки
15)	если мы получаем ink_263 и link_452, то мы передаём их в качестве параметров в функцию volume_calculation()
16)	рассчитываем разницу между объёмами холодильников Саратов-263 и Сартов-452
17)	узнаем наибольшее и наименьшее из этих чисел
18)	далее из наибольшего отнимаем наименьшее
19)	выводим ответ

Работа с SQL
Задание
Соберите данные о моделях холодильников Саратов с маркетплейса beru.ru: URL, название, цена, размеры, общий объем, объем холодильной камеры.
Создайте соответствующие таблицы в SQLite базе данных и загрузите полученные данные в таблицу beru_goods.
Для парсинга можно использовать зеркало страницы beru.ru с результатами для холодильников Саратов по адресу:
video.ittensive.com/data/018-python-advanced/beru.ru/
Решение:
1)	подключаем нужные нам библеотеки
2)	создаём функцию, которая будет приводить к числу, передаваемою ей в качестве параметра, строку
3)	проверяем что символ - цифра, и объединяем его, с возвращаемым значением, через пустую строку
4)	получаем контент с сайта beru.ru, с адреса, который представляет собой страницу, на которой в поле поиска товаров выбран "Саратов", + ссылка на детальную страницу товара
5)	преобразуем контент в объект
6)	получаем название холодильника, оно храниться в первом теге h1
7)	который имеет класс "_3TfWusA7bt", преобразуем полученную информацию в текст
8)	находим цену холодильника
9)	получаем первый тег span, который имеет "data-tid", равный "c3eaad93"
10)	получаем все теги "sapn", которые имеют класс "sapn", преобразуем информацию в текст
11)	именно в этих тегах хранятся нужные нам, параметры холодильника
12)	создаём переменные для хранения параметров, на тот случай, если при паргсинге они вдруг не будут определены: ширины, глубины, высоты, общий объем, объем холодильной камеры
13)	обходим циклом данные в которых храниться информация о параметрах холодильника
14)	преобразуем эту информацию в текст
15)	если в теге присутствует данная строка "ШхВхГ", то эту строку мы разделяем по двоеточию, затем вторую часть данной строки (индекс [1]) мы ещё раз делим по символу "х", первое значение в получившейся строке, является значением ширины
16)	получаем его, и преобразуем к типу данных float, глубина, второе значение, высота третье, 
17)	чтобы избавиться от сантиметров, делим строку по пробелу, и берём её левую часть, 
18)	если в теге присутствует данная строка "общий объем", то мы присваиваем переменной volume, значение этой строки
19)	функция возвращает ссылку детальной страницы холодильника, название, цену, ширину, глубину, высоту, общий объём и объём холодильной камеры
20)	в созданную, для получения данных со страницы функцию, передаём одну из детальных страниц, модели холодильника
21)	получаем контент со страницы, на которой хранятся все ссылки на детальные страницы холодильника
22)	преобразуем контент в объект
23)	получаем все данные со из ссылок, с атрибутом "а", с классом "grid_snippet_react-link"
24)	создаём массив, для того чтобы составить список ссылок детальных страниц
25)	обходим циклом набор полученных ссылок если у ссылки есть атрибут href и в её текстовом представлении есть значение "Сартов"
26)	в массив data добавляем результат работы функции find_data()
27)	подключаемся к базе данных "data.db3"
28)	в базе данных создаём таблицу "beru_goods", полями id (первичный ключ, автоинкрементен, не null), url (text), title (text), price (целочисленное значение, по умолчанию равно 0), url (text), title (text), price (целочисленное значение, по умолчанию равно 0), depth (дробное знчение, по умолчанию равно 0.0), height  (дробное знчение, по умолчанию равно 0.0), volume (целочисленное значение, по умолчанию равно 0), freezer price (целочисленное значение, по умолчанию равно 0)
29)	выполняем коммит результата
30)	в базу данных, с помощью запроса INSERT мы передаём данные, в таблицу beru_goods, в качестве передаваемых параметров указываем,  массив data, используем executemany, для того, чтобы добавить множество строк одновременно
31)	выводим все значения из созданной базы данных
32)	закрываем соединения с базой данных

Часть 3: визуализация данных
Основы Matplotlib

Задание
Загрузите данные по ЕГЭ за последние годы
https://video.ittensive.com/python-advanced/data-9722-2019-10-14.utf.csv
выберите данные за 2018-2019 учебный год.
Выберите тип диаграммы для отображения результатов по административному округу Москвы, постройте выбранную диаграмму для количества школьников, написавших ЕГЭ на 220 баллов и выше.
Выберите тип диаграммы и постройте ее для районов Северо-Западного административного округа Москвы для количества школьников, написавших ЕГЭ на 220 баллов и выше.
Сколько школьников в Строгино, написавших ЕГЭ
Решение:
1)	подключаем нужные нам библиотеки
2)	вывод matplotlib прямо в окне браузера
3)	получаем данные по указанной ссылки, в качестве разделителя указываем ";"
4)	преобразуем данные по районам (чтобы устранить дубликаты и сделать подписи короче), удаляем из название слово "район", дополнительно назначаем район, категорией, чтобы группировка происходила быстрее
5)	преобразуем данные по округам, удаляем все слова кроме перового, данные по округам также преобразуем в категорию
6)	установим индекс по году, выполним сортировку, чтобы получить данные только за 2018-2019 год, затем сбросим индекс
7)	поскольку данных по округам и районам достаточно много, и вместе они образуют совокупность
8)	будем использовать круговую диаграмму, выведем две круговые диаграммы в одну строку
9)	берём холст 12 на 12
10)	добавляем на него первую область, 2 столбца, 1 строкой
11)	строим диаграмму распределения отличников по округам, добавим заголовок данных "ЕГЭ в Москве", размер шрифта 20 пикселей
12)	в качестве индекса, выбираем серию данных "AdmArea" (административные округа)
13)	теперь отсечём данные только отличников, сгруппируем данные по округам, выведем сумму на круговой диаграмме
14)	для второй диаграммы выберем все данные в Северо-западном округе, добавим область для вывода данных, 
15)	в эту область выведем заголовок: "ЕГЭ в Северо-Западном административном округе"
16)	получаем данные по Северо-Западному административному округу, сбрасываем индекс, затем устанавливаем индекс по серии данных "District", то есть по районам
17)	после этого отсечём только отличников, сгруппируем по серии данных "District",
18)	выполним операцию суммирования
19)	вычислим общее число отличников по районам
20)	построим круговую диаграмму по районам, округляем значения отличников, а затем приводим их к целому числу

Визуализация зависимостей

Задание
Загрузите данные по итогам марафона
https://video.ittensive.com/python-advanced/marathon-data.csv
Приведите время половины и полной дистанции к секундам.
Найдите, данные каких серии данных коррелируют (используя диаграмму pairplot в Seaborn).
Найдите коэффициент корреляции этих серий данных, используя scipy.stats.pearsonr.
Постройте график jointplot для коррелирующих данных.
Решение: 
1)	подключаем нужные нам библиотеки
2)	создаём функцию для конвертации времени в общее количество часов, минут и секунд, функция будет принимать на вход строку, описывающую время и возвращать через генератор, перебирающий пары значений, число и его вес в секундах
3)	затем, мы возьмём сумму этих произведений чисел и их весов, и вернём из функции значение часов, минут и секунд получим, разделив исходную строку времени по двоеточию
4)	получаем нужные нам данные в качестве разделителя указываем запятую
5)	применяем функцию для конвертации времени, к сериям данных "split" и "final"
6)	построим парный график, чтобы посмотреть, какие данные с какими коррелируют
7)	для групп, или категорий используем пол спортсменов
8)	строим корреляционный график jointplot(), для серий данных "split" и "final", и найдём коэффициент корреляции Пирсона
9)	дополнительно выводим коэффициент Пирсона, по двум сериям данных отдельно

Временные ряды

Задание
Используя данные индекса РТС за последние годы
https://video.ittensive.com/python-advanced/rts-index.csv
постройте отдельные графики закрытия (Close) индекса по дням за 2017, 2018, 2019 годы в единой оси X.
Добавьте на график экспоненциальное среднее за 20 дней для значения Max за 2017 год.
Найдите последнюю дату, когда экспоненциальное среднее максимального дневного значения (Max) в 2017 году было больше, чем соответствующее значение Close в 2019 году (это последнее пересечение графика за 2019 год и графика для среднего за 2017 год).
Решение:
1)	подключаем нужные нам библиотеки
2)	получаем необходимые данные
3)	преобразуем строковые значения в серии данных "Date", к типу данных "дата"
4)	указываем dayfirst=True, чтобы все даты корректно преобразовались из русского формата, в английский
5)	выполняем сортировку данных, от минимального к максимального
6)	в качестве индекса используем серию данных "Date"
7)	переиндексируем все данные, заполним пустые даты предыдущими значениями, это понадобиться нам для сравнения данных по годам, чтобы в каждый день года, у нас было хотя бы одно значение
8)	добавим ещё одну серию данных, "день года" для подписи по осям x
9)	назначаем название индекса, которое потерялось при переиндексации данных
10)	сортируем по индексу, чтобы развернуть данные в правильном хронологическом порядке
11)	для данных за 2019 год создадим отдельный набор, чтобы в последствии искать искомую, дату превышения, как пересечение его с набором за 2017 год
12)	аналогичным образом и создадим набор данных и для 2017 года, для него сразу возьмём экспоненциальное среднее, со сдвигом 20 от значения максимума 
13)	создаём наш холст, размером 12 на 8, добавляем на него 1 столбец, 1 строка, 1 подобласть
14)	наносим данные на область area, с названием "2019" цвет красный, толщина 3
15)	наносим обычные данные за 2017 год в виде оранжевой линии
16)	переопределяем индекс, и назначаем в качестве индекса серию данных "Close"
17)	а также за 2018 год, виде ещё одной линии
18)	добавляем легенду
19)	находим дату, когда показатели индекса РТС, превзошли показатели за 2017 год, фильтруем данные за 2019 год, когда "Close" (закрытие дня), было больше максимума, аналогичного дня за 2017 год  
20)	выставляем индекс по дате, отсортируем по индексу
21)	выведем первое значение, то есть последнюю дату, когда дневной максимум в 2017 году, был больше закрытия, в соответствующим дне 2019 года 
Гео-данные и картограммы
Задание
Изучите набор данных по объектам культурного наследия России (в виде gz-архива):
https://video.ittensive.com/python-advanced/data-44-structure-4.csv.gz
и постройте фоновую картограмму по количеству объектов в каждом регионе России, используя гео-данные
https://video.ittensive.com/python-advanced/russia.json
Выведите для каждого региона количество объектов в нем.
Посчитайте число объектов культурного наследия в Татарстане.
Решение:
1)	загружаем файл локально, так как из его большого объёма, могут возникнуть сложности при работе, будем использовать только колонки "Объект" и "Регион"
2)	приводим регион к верхнему регистру, важно чтобы регистр "региона", в обоих наборах данных был одинаковый 
3)	выполняем группировку по региону, посчитаем число объектов по каждому региону, находим все расхождения, которые уже выведены в наборе нулевых значений, в результирующем объединённом наборе данных
4)	загружаем гео-данные
5)	приводим их к миркатеру
6)	Название регионов в геоданных приводим к верхнему регистру
7)	выполняем переманивание регионов в "гео-наборе", чтобы унифицировать их с основным набором данных
8)	осуществляем объединение наборов данных, (осинового и "гео"), слияние выполняем по региону, за исходный набор данных возьмём "гео", в него вольём данные по объектам, чтобы вывести
9)	отображаем эти данные на картограмме
10)	чтобы найти проблемы по регионам, какие названия у нас расходятся выведем все строки где поля объект, значит число объектов в регионе "null", то есть объединение корректно по этому региону не прошло (региона не было в исходном наборе)
11)	Создаём холст, добавляем туда область, наносим область на картограмму, будем использовать количество объектов культурного наследия для числовой градации
12)	обрезаем картограмму, убираем Чукотку, и всё что западнее Калининграда, задаём лимит по оси x, так как координаты указаны в десятках миллионов (1е7), поэтому нам нужен диапазон от 2 миллионов, до 20 миллионов
13)	дополнительно наносим аннотацию, в виде числа объектов в каждом регионе
14)	число объектов разместим в центре полигона, отвечающим за конкретный регион
15)	выводим число объектов для Алтайского Края

Часть 4: отчеты и автоматизация
Работа с PDF
Задание
Используя данные по посещаемости библиотек в районах Москвы
https://video.ittensive.com/python-advanced/data-7361-2019-11-28.utf.json
постройте круговую диаграмму суммарной посещаемости (NumOfVisitors) 20 наиболее популярных районов Москвы.
Создайте PDF отчет, используя файл
https://video.ittensive.com/python-advanced/title.pdf
как первую страницу. На второй странице выведите итоговую диаграмму, самый популярный район Москвы и число посетителей библиотек в нем.

Решение:
1)	подключаем все нужные нам библиотеки
2)	создаём функцию, для извлечения название района, из поля District, функция берёт значение серии ObjectAddress, находит в этом значении поля District, приводит это поля к списку, и возвращает первое значение из этого списка, по факту будет вычленять первый найденный District из словаря ObjectAddress, получаем нужные данные, с помощью запроса с методом get
3)	полученные данные передаём во фрейм, результат разбора json-файла, также заполняем нулями отсутствующие значения
4)	для группировки по районам, нам нужно извлечь название района из поля District, которое является, json разобранным в словарь
5)	после получения района для всех значений данных, можно сгруппировать по нему, и отсортировать по часу посетителей библиотек, в порядке убывания
6)	создаём холст   
7)	наносим на него подобласть
8)	строим результирующую диаграмму из 20 самых популярных районов, для большей читаемости уберём районы из подписи на диаграмме, задав пустые labels ровно по числу наших районов
9)	переносим все наши районы в легенду, это будет индекс из нашего набора данных, легенду выведем справа от диаграммы, сохраняем график в файл, для дальнейшей вставки в наш отчёт
10)	начинаем формирования отчёта, задаём шрифты
11)	задаём холст с размерами, наносим на холст данные
12)	 создаём вторую страницу отчёта
13)	вставляем диаграмму, в виде отдельного изображения
14)	из того файла, что мы сохранили ранее
15)	дополнительно выедем информацию по самому популярному району
16)	это первый район в отсортированном списке
17)	выводим первое число посетителей в нашем кортеже
18)	объединяем сгенерированный отчёт, и титульную страницу через PdfFileMerger()
19)	создаём PDF файл report.pdf

Базовые отчеты
Задание
Сгенерируйте PDF документ из списка флагов и гербов районов Москвы:
https://video.ittensive.com/python-advanced/data-102743-2019-11-13.utf.csv
На каждой странице документа выведите название геральдического символа (Name), его описание (Description) и его изображение (Picture).
Для показа изображений используйте адрес
https://op.mos.ru/MEDIA/showFile?id=XXX
где XXX - это значение поля Picture в наборе данных. Например:
https://op.mos.ru/MEDIA/showFile?id=8466da35-6801-41a9-a71e-04b60408accb
Решение:
1)	подключаем нужные библиотеки
2)	загружаем файл с данными
3)	формируем html документ, в заголовке указываем "Геральдические символы Москвы", кодировка utf-8, после этого нам нужно добавить в документ, постраничный вывод данных
4)	выведем заголовки одного уровня, и зададим стили для всех кроме первого
5)	перебираем в цикле наш набор данных data.iterrows()
6)	только для первого элемента мы не будем задавать стиль
7)	для всех остальных задаём стили, и ставим разрыв страницы, после первого заголовка, таким образом мы получим каждый геральдический символ с названием, на отдельной страницы
8)	после заголовка, который будет обеспечивать разрыв страницы, мы выведем изображения геральдического изображения, в увеличенном виде, используем для этого атрибут style и свойство width (ширина), сделаем отступ слева margin-left:10%, источник изображения зададим через ссылку, в нужном формате, возьмём исходный формат ссылки, и добавим к нему значение поля Picture из нашего кортежа данных
9)	выводим описание символа, увеличиваем шрифт для читаемости с помощью font-size, выведем свойство Description у нашего кортежа
10)	конфигурируем pdfkit стандартным образом, указав путь до бинарного файла
11)	зададим стандартные настройки: размер страницы, пагинацию (вывод страницы на каждой страницы)
12)	сохраняем результат, в виде файла heraldic.pdf

Генерация отчетов
Задание
Используя данные по активностям в парках Москвы
https://video.ittensive.com/python-advanced/data-107235-2019-12-02.utf.json
Создайте PDF отчет, в котором выведите:
1. Диаграмму распределения числа активностей по паркам, топ10 самых активных
2. Таблицу активностей по всем паркам в виде Активность-Расписание-Парк
Решение:
1)	подключаем нужные нам библиотеки
2)	получаем нужные данные
3)	формируем набор данных только из колонок "CourseName", "CoursesTimetable", "NameOfPark"именно эти колонки нужны нам для вывода в отчёте
4)	получаем название парка из комбинированной серии, получаем значение value словаря
5)	переименовываем колонки для отчёта
6)	для ответа на поставленный вопрос найдём активность Тайцзицюань, и выведем число записей с этой активностью
7)	формируем диаграмму активности по паркам
8)	создаём холст
9)	проводим группировку данных по парку, отсортируем эту группировку в порядке убывания, чтобы взять первые 20 значений по посещаемости, и нанести их на круговую диаграмму
10)	для временного хранения бинарных файлов изображения используем BytesIO() и его дальнейшего преобразование в base64 – формат
11)	по факту у нас будет некоторый указатель в памяти, который мы используем, для хранения данных изображения, преобразовываем бинарные данные к base64, данные декодируем в UTF – 8
12)	преобразовываем бинарные данные к base64, данные декодируем в UTF – 8
13)	указываем максимальное количество символов в ячейках
14)	Формируем html - отчёт, в отчёте выводим изображение, уровень активности парка и расписание
15)	генерируем PDF - файл, из html - строки, используя pdfkit
16)	сохраняем полученный результат в файл parks.pdf

Отправка email и интеграция
Задание
Соберите отчет по результатам ЕГЭ в 2018-2019 году, используя данные
https://video.ittensive.com/python-advanced/data-9722-2019-10-14.utf.csv
и отправьте его в HTML формате по адресу support@ittensive.com, используя только Python.
В отчете должно быть:
•	общее число отличников (учеников, получивших более 220 баллов по ЕГЭ в Москве),
•	распределение отличников по округам Москвы,
•	название школы с лучшими результатами по ЕГЭ в Москве.
Диаграмма распределения должна быть вставлена в HTML через data:URI формат (в base64-кодировке).
Дополнительно: приложите к отчету PDF документ того же содержания (дублирующий письмо).
Решение:
1)	подключаем нужные нам библиотеки
2)	получаем необходимые данные
3)	выделяем из данных результаты только 2018-2019 годов
4)	ищем лучшею школу по результатам ЕГЭ, выполняем сортировку по PASSES_OVER_220, и берём первое значение, сортировка значений также позволяет вынести два самых малочисленных значения, чтобы подписи поместились на графике
5)	выполняем группировку по административному округу, предварительно уберём из этой серии данных все слова, кроме первого, для того чтобы подписи данных были короче
6)	считаем общее число отличников, оно нужно для отчёта и для вывода доли
7)	создаём холст
8)	на холст задаём список explode, список секторов
9)	указываем меру их выноса из основной диаграммы
10)	создаём круговую диаграмму по округа
11)	в подписи передадим пустой набор данных по числу округов
12)	выведем названия
13)	создаём авто подписи данных, которые сформируем, из доли точного значения отличников по округам
14)	список для выноса секторов
15)	справа выведем легенд с подписями округов  
16)	сохраняем диаграмму, как изображения для выставки изображения в отчёт
17)	для выставки изображения в отчёт, преобразуем его в base64 – кодировку стандартным образом
18)	задаём настройку pandas по длине значения в колонке
19)	формируем html - отчёт со всеми данными, задаём кодировку, заголовок, вставим суммарное значение числа отличников, распределение по округам, нашу диаграмму, и название лучшей школы
20)	из html - документа формируем pdf - отчёт, через pdfkit, конфигурируем бинарный файл, задаём настройки, размер страницы и вывод номера страницы, на каждой страницы
21)	вызываем генерацию pdf документа, сохраняем его как ege.best.pdf в качестве параметров передаём config и options
22)	приступаем к отправке письма, создаём новый объект MIMEMultipart()
23)	задаём ему поля, отправитель, тему, тип, и адрес отправки
24)	к телу письма прикрепим наш html – документ
25)	в качестве вложения добавляем наш pdf – отчёт
26)	подключаемся к почтовому серверу и отправляем письмо на адрес support@ittensive.com также указываем логин и пароль
27)	закрываем соединение с сер
